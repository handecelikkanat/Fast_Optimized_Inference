{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax device count: 1\n",
      "jax local device count:  1\n",
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jax\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# JAX setup\n",
    "JAX_SEED=42\n",
    "print('jax device count:', jax.device_count())  # total number of accelerator devices in the cluster\n",
    "print('jax local device count: ', jax.local_device_count())  # number of accelerator devices attached to this host\n",
    "\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyS6rRC_lgGY",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simple Speed Comparison: BERT vs JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d1ndJdHjHqg",
    "outputId": "a82dfbb9-1d11-4d42-b77f-67c5692ca15a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hande/.virtualenvs/langid/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'bias'), ('pooler', 'dense', 'kernel')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, FlaxBertModel\n",
    "import jax\n",
    "from jax import grad, jit\n",
    "import jax.numpy as np\n",
    "np.set_printoptions(linewidth=240)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "jax_model = FlaxBertModel.from_pretrained('bert-base-uncased')\n",
    "pt_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTxoftzOjVyE",
    "outputId": "47e548d1-eb03-4819-cf48-16daebd62b3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1914, -0.5446, -0.1544,  ..., -0.5098,  0.1434,  0.4844],\n",
       "         [-0.4116, -0.5880, -0.7113,  ...,  0.3556,  0.7013, -0.3451],\n",
       "         [ 0.1175, -0.4358, -0.1766,  ...,  0.0241,  0.0956, -0.1309],\n",
       "         ...,\n",
       "         [ 0.0185, -0.2742, -0.5359,  ..., -0.6504, -0.0117, -0.2525],\n",
       "         [ 0.7980, -0.0621, -0.4312,  ...,  0.0909, -0.4904, -0.2666],\n",
       "         [ 0.6253, -0.1266, -0.2116,  ...,  0.5051, -0.5687, -0.3665]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pt_forward():\n",
    "    inputs = tokenizer(\"You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\", return_tensors=\"pt\")\n",
    "    outputs = pt_model(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "pt_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGSMrQjzjpuy",
    "outputId": "e0fb66f9-2ba2-485f-8872-5343ce8f28e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.5 ms ± 765 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pt_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjZhZ9qGjqui",
    "outputId": "a4d83d32-10ee-44a9-edd7-f39c34e34454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.19064319, -0.54382896, -0.15333818, ..., -0.5101217 ,  0.14285733,  0.48461798],\n",
       "        [-0.41225404, -0.5879406 , -0.7097802 , ...,  0.35409293,  0.70039594, -0.34506193],\n",
       "        [ 0.11897378, -0.43416384, -0.17663035, ...,  0.02296186,  0.09597686, -0.13082281],\n",
       "        ...,\n",
       "        [ 0.01874121, -0.27286923, -0.53406894, ..., -0.6514603 , -0.01144049, -0.2528037 ],\n",
       "        [ 0.7958135 , -0.06071458, -0.4304184 , ...,  0.08984526, -0.48966262, -0.2661015 ],\n",
       "        [ 0.62361646, -0.12573534, -0.21107566, ...,  0.5039953 , -0.5679369 , -0.36577556]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jax_forward():\n",
    "    inputs = tokenizer(\"You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\", return_tensors='jax')\n",
    "    outputs = jit(jax_model)(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "jax_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58TgXoPdjt0x",
    "outputId": "9d0bd12a-2f6d-4072-cc40-2892640a67d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12 ms ± 143 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jax_forward().block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R69buRHmFA9"
   },
   "source": [
    "### Langid Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eiu3UnjmHKG",
    "outputId": "152e9215-de2e-40a8-ea83-68c8d58611ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Text', 'Language'],\n",
      "        num_rows: 9303\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Text', 'Language'],\n",
      "        num_rows: 1034\n",
      "    })\n",
      "})\n",
      "['English', 'German', 'Dutch', 'Tamil', 'Greek', 'Greek', 'French', 'Spanish', 'Russian', 'Malayalam']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from difflib import get_close_matches\n",
    "\n",
    "DATAPATH = '../data/language_detection.csv'\n",
    "\n",
    "DATA_PERCENT_LIMIT = 100\n",
    "TEST_SPLIT = 0.1\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "split = f'train[:{DATA_PERCENT_LIMIT}%]' if DATA_PERCENT_LIMIT else 'train'\n",
    "dataset = load_dataset(\"csv\", split=split, data_files=DATAPATH, encoding='utf-8').shuffle(seed=SEED)\n",
    "dataset = dataset.train_test_split(test_size=TEST_SPLIT, seed=SEED)\n",
    "\n",
    "N_LABELS = len(set(dataset['train']['Language']))\n",
    "\n",
    "print(dataset)\n",
    "print(dataset['train'][:10]['Language'])\n",
    "\n",
    "LANG2ID = {\n",
    "    'English': 0,\n",
    "    'Malayalam': 1,\n",
    "    'Hindi': 2,\n",
    "    'Tamil': 3,\n",
    "    'Kannada': 4,\n",
    "    'French': 5,\n",
    "    'Spanish': 6,\n",
    "    'Portuguese': 7,\n",
    "    'Italian': 8,\n",
    "    'Russian': 9,\n",
    "    'Sweedish': 10,\n",
    "    'Dutch': 11,\n",
    "    'Arabic': 12,\n",
    "    'Turkish': 13,\n",
    "    'German': 14,\n",
    "    'Danish': 15,\n",
    "    'Greek': 16\n",
    "    }\n",
    "\n",
    "def lang_to_id(lang):\n",
    "      return LANG2ID[get_close_matches(lang, LANG2ID.keys())[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518,
     "referenced_widgets": [
      "9cc887b025b24cff8b4b8184e99ed639",
      "43710f566333424c9185ceba18ff3ee7",
      "6d6ed1bfb29749fca673c486d2d0a824",
      "5e95917331af48c09faf9d1dfbafe915",
      "a1835e1a5d884e80a126b419a69b361b",
      "45037c38977c4a11ad72ac83d2fe993f",
      "423ec32b0962400583d6c00970ca8cfc",
      "60ce3dd895e5468aa7fdfe9845495624",
      "c328efe9a61e476a9b1f6880c57557ef",
      "d2ff778f59c84c5f84e762fb50000db1",
      "a0f7b3b956574e4b8cd0f9ff1c7a4ae5",
      "fb33d0aad8704f4da44e22096bfe7eaf",
      "c4c9e86eae6b4e4883061ec8f59305ac",
      "7aaa0aea039542e1b9438ef1336a55e0",
      "abf65fd7765d425aa9749fe7dbe28403",
      "15c06211b1fc47718006c09c951ba009",
      "fd0de6f58b414f0d9e156e5a7610d862",
      "3f431a8aa6924f25ae14e1d432dca235",
      "7d159038fd204086b153b120333bcc4f",
      "504a496205ee409ead86ee59a55ec565",
      "33aa37bed5e948138942773a41efdb10",
      "e4e03a2a6c654128a6719fee1c2fdc8a"
     ]
    },
    "id": "bkitOldIlNYa",
    "outputId": "1cf8a6af-31ad-4afa-812e-93f29d24ad4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f4dbb33abb4176b0cdbc3dc53bc464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f1c01ab8df4f9c8446fc56870177fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1034 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Text', 'Language', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 9303\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Text', 'Language', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1034\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# BERT tokenize\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    batch = tokenizer(examples['Text'], padding=\"max_length\", truncation=True)\n",
    "    batch['labels'] = [lang_to_id(lang) for lang in examples['Language']]\n",
    "    return batch\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40548-Eal6E-"
   },
   "source": [
    "### PT BERT Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Psbf9FZ-5YpR",
    "outputId": "5a36fc92-720c-44e3-bdf7-a0774ae7a498"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2326' max='2326' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2326/2326 2:41:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362411</td>\n",
       "      <td>0.879110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.324692</td>\n",
       "      <td>0.901354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.663100</td>\n",
       "      <td>0.293299</td>\n",
       "      <td>0.906190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.663100</td>\n",
       "      <td>0.268090</td>\n",
       "      <td>0.906190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.217692</td>\n",
       "      <td>0.913926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.280070</td>\n",
       "      <td>0.906190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.255958</td>\n",
       "      <td>0.907157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>0.275717</td>\n",
       "      <td>0.911025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>0.296333</td>\n",
       "      <td>0.908124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.225104</td>\n",
       "      <td>0.917795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.201813</td>\n",
       "      <td>0.917795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT train time: 9713.031286001205s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "TRAIN_STEPS_LIMIT = -1\n",
    "N_EPOCHS = 1\n",
    "\n",
    "OUTPUT_PATH = '../models/pt'\n",
    "\n",
    "# Free memory\n",
    "gc.collect()\n",
    "\n",
    "# load pre-trained\n",
    "pt_model = BertForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=N_LABELS)\n",
    "\n",
    "# fine-tune\n",
    "log_dir = os.path.join(OUTPUT_PATH, strftime(\"%Y%m%d-%H%M\", gmtime()))\n",
    "try:\n",
    "    os.system(f'mkdir {log_dir}')\n",
    "except:\n",
    "    print('log dir exists, aborting')\n",
    "    sys.exit(1)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=log_dir,\n",
    "                                  label_names=['labels'],\n",
    "                                  num_train_epochs=N_EPOCHS,\n",
    "                                  max_steps = TRAIN_STEPS_LIMIT, #overrides num_train_epochs\n",
    "                                  per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "                                  eval_strategy=\"steps\",\n",
    "                                  eval_steps=500)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "pt_trainer = Trainer(\n",
    "    model=pt_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "pt_train_start_time = time.time()\n",
    "pt_trainer.train()\n",
    "pt_train_end_time = time.time()\n",
    "print(\"PT train time: %ss\" % (pt_train_end_time - pt_train_start_time))    # PT train time: 9713.031286001205s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1034' max='1034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1034/1034 06:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT eval time: 378.33ms per iteration (391.20s / 1034 data points)\n"
     ]
    }
   ],
   "source": [
    "# PT BERT evaluate\n",
    "\n",
    "CHECKPOINT = '../../models/langid/pt/20250318-0945/checkpoint-2326'\n",
    "\n",
    "# load saved checkpoint\n",
    "pt_checkpoint = BertForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=N_LABELS)\n",
    "\n",
    "pt_eval_trainer = Trainer(\n",
    "    model=pt_checkpoint,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "pt_eval_start_time = time.time()\n",
    "pt_eval_trainer.evaluate()\n",
    "pt_eval_end_time = time.time()\n",
    "print(f\"PT eval time: {(pt_eval_end_time - pt_eval_start_time) / len(tokenized_datasets['test']) * 1000:0.2f}ms per iteration \"\n",
    "      f\"({(pt_eval_end_time - pt_eval_start_time):0.2f}s / {len(tokenized_datasets['test'])} data points)\") # PT eval time: 378.33ms per iteration (391.20s / 1034 data points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JAX BERT Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX BERT train\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import flax\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import traverse_util\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from flax.training import train_state\n",
    "\n",
    "N_EPOCHS = 1\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# Free memory\n",
    "gc.collect()\n",
    "\n",
    "# setup\n",
    "num_train_steps = len(dataset['train']) // TRAIN_BATCH_SIZE * N_EPOCHS\n",
    "learning_rate_function = optax.linear_schedule(init_value=LEARNING_RATE, end_value=0, transition_steps=num_train_steps)\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    logits_function: Callable = flax.struct.field(pytree_node=False)\n",
    "    loss_function: Callable = flax.struct.field(pytree_node=False)\n",
    "\n",
    "def decay_mask_fn(params):\n",
    "    flat_params = traverse_util.flatten_dict(params)\n",
    "    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n",
    "    return traverse_util.unflatten_dict(flat_mask)\n",
    "\n",
    "def adamw(weight_decay):\n",
    "    return optax.adamw(learning_rate=learning_rate_function, b1=0.9, b2=0.999, eps=1e-6, weight_decay=weight_decay, mask=decay_mask_fn)\n",
    "\n",
    "def loss_function(logits, labels):\n",
    "  xentropy = optax.softmax_cross_entropy(logits, onehot(labels, num_classes=N_LABELS))\n",
    "  return jnp.mean(xentropy)\n",
    "     \n",
    "def eval_function(logits):\n",
    "    return logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: {('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('classifier', 'kernel'), ('classifier', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxBertForSequenceClassification, BertConfig\n",
    "\n",
    "# load pre-trained\n",
    "config = BertConfig.from_pretrained('google-bert/bert-base-cased', num_labels=N_LABELS)\n",
    "jax_model = FlaxBertForSequenceClassification.from_pretrained('google-bert/bert-base-cased', config=config, seed=JAX_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../models/jax'\n",
    "log_dir = os.path.join(OUTPUT_PATH, strftime(\"%Y%m%d-%H%M\", gmtime()))\n",
    "try:\n",
    "    os.system(f'mkdir {log_dir}')\n",
    "except:\n",
    "    print('log dir exists')\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=jax_model.__call__,\n",
    "    params=jax_model.params,\n",
    "    tx=adamw(weight_decay=0.01),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "\n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    grad_function = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_function(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = jax.lax.pmean({\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}, axis_name=\"batch\")\n",
    "    return new_state, metrics, new_dropout_rng\n",
    "\n",
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.logits_function(logits)\n",
    "\n",
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(rng, dataset, batch_size):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        del batch['Text']\n",
    "        del batch['Language']\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "        yield batch\n",
    "\n",
    "def eval_data_loader(dataset, batch_size):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        del batch['Text']\n",
    "        del batch['Language']        \n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = flax.jax_utils.replicate(state)\n",
    "num_labels = flax.jax_utils.replicate(N_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(JAX_SEED)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n",
    "\n",
    "#for i, epoch in enumerate(tqdm(range(1, N_EPOCHS + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n",
    "rng, input_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e909ebc35254e4bb365a6bc63ee0ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax train time: 417.2018005847931s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# train\n",
    "jax_train_start_time = time.time()\n",
    "with tqdm(total=len(tokenized_datasets['train']) // TRAIN_BATCH_SIZE, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "  for batch in train_data_loader(input_rng, tokenized_datasets['train'], TRAIN_BATCH_SIZE):\n",
    "    state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "jax_train_end_time = time.time()\n",
    "print(\"Jax train time: %ss\" % (jax_train_end_time - jax_train_start_time)) #Jax train time: 411.633828163147s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b279be432644dffb7479c5a317dfe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating...:   0%|          | 0/1034.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax eval time: 19.69ms per iteration (20.36s / 1034 data points)\n",
      "Eval accuracy: 0.918\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from transformers import FlaxBertForSequenceClassification, BertConfig\n",
    "import evaluate\n",
    "\n",
    "\n",
    "CHECKPOINT = '../../langid/models/jax/20250318-0945/checkpoint-2000'\n",
    "\n",
    "# load saved checkpoint\n",
    "config = BertConfig.from_pretrained(CHECKPOINT, num_labels=N_LABELS)\n",
    "jax_checkpoint = FlaxBertForSequenceClassification.from_pretrained(CHECKPOINT, config=config, seed=JAX_SEED)\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=jax_checkpoint.__call__,\n",
    "    params=jax_checkpoint.params,\n",
    "    tx=adamw(weight_decay=0.01),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")\n",
    "\n",
    "jax_acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# evaluate\n",
    "jax_eval_start_time = time.time()\n",
    "with tqdm(total=len(tokenized_datasets['test'])/ EVAL_BATCH_SIZE, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n",
    "  for batch in eval_data_loader(tokenized_datasets['test'], EVAL_BATCH_SIZE):\n",
    "      labels = batch.pop(\"labels\")   \n",
    "      predictions = parallel_eval_step(state, batch)    \n",
    "      jax_acc_metric.add_batch(predictions=list(itertools.chain.from_iterable(predictions)), references=list(itertools.chain.from_iterable(labels)))\n",
    "      progress_bar_eval.update(1)\n",
    "jax_eval_end_time = time.time()\n",
    "print(f\"Jax eval time: {(jax_eval_end_time - jax_eval_start_time) / len(tokenized_datasets['test']) * 1000:0.2f}ms per iteration \"\n",
    "      f\"({(jax_eval_end_time - jax_eval_start_time):0.2f}s / {len(tokenized_datasets['test'])} data points)\")\n",
    "\n",
    "jax_eval_acc_metric = jax_acc_metric.compute()\n",
    "\n",
    "loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n",
    "jax_eval_acc_score = round(list(eval_metric.values())[0], 3)\n",
    "metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "print(f\"Eval {metric_name}: {jax_eval_acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjCBNlOJntdV"
   },
   "source": [
    "### Fasttext train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5076ca320f549ecbe826abe0dc18676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec66f2c59f2d44cc8f1899bdcaad2138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1034 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[140]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(tokenized_datasets[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28minput\u001b[39m = data[\u001b[33m'\u001b[39m\u001b[33mText\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     prediction = \u001b[43mfasttext_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     fasttext_acc_metric.add_batch(predictions=[prediction], references=[lang_to_id(data[\u001b[33m'\u001b[39m\u001b[33mLanguage\u001b[39m\u001b[33m'\u001b[39m])])\n\u001b[32m     45\u001b[39m fasttext_eval_end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/langid/lib/python3.11/site-packages/fasttext/FastText.py:239\u001b[39m, in \u001b[36m_FastText.predict\u001b[39m\u001b[34m(self, text, k, threshold, on_unicode_error)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m     probs, labels = ([], ())\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m labels, \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword."
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import fasttext\n",
    "from difflib import get_close_matches\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "'''\n",
    "LANG2ID = {\n",
    "    '__label__eng': 0,\n",
    "    'Malayalam': 1,\n",
    "    'Hindi': 2,\n",
    "    'Tamil': 3,\n",
    "    'Kannada': 4,\n",
    "    'French': 5,\n",
    "    'Spanish': 6,\n",
    "    'Portuguese': 7,\n",
    "    'Italian': 8,\n",
    "    'Russian': 9,\n",
    "    'Sweedish': 10,\n",
    "    'Dutch': 11,\n",
    "    'Arabic': 12,\n",
    "    'Turkish': 13,\n",
    "    'German': 14,\n",
    "    'Danish': 15,\n",
    "    'Greek': 16\n",
    "    }\n",
    "\n",
    "def lang_to_id(lang):\n",
    "      return LANG2ID[get_close_matches(lang, LANG2ID.keys())[0]]\n",
    "\n",
    "\n",
    "'__label__eng_Latn'\n",
    "af als am an ar arz as ast av az azb ba bar bcl be bg bh bn bo bpy br bs bxr ca cbk ce ceb ckb co cs cv cy da de diq dsb dty dv el eml en eo es et eu fa fi fr frr fy ga gd gl gn gom gu gv he hi hif hr hsb ht hu hy ia id ie ilo io is it ja jbo jv ka kk km kn ko krc ku kv kw ky la lb lez li lmo lo lrc lt lv mai mg mhr min mk ml mn mr mrj ms mt mwl my myv mzn nah nap nds ne new nl nn no oc or os pa pam pfl pl pms pnb ps pt qu rm ro ru rue sa sah sc scn sco sd sh si sk sl so sq sr su sv sw ta te tg th tk tl tr tt tyv ug uk ur uz vec vep vi vls vo wa war wuu xal xmf yi yo yue zh\n",
    "'''\n",
    "\n",
    "fasttext_model_path = hf_hub_download(repo_id=\"facebook/fasttext-language-identification\", \n",
    "                                      filename=\"model.bin\", \n",
    "                                      cache_dir=\"../../models/langid/fasttext/cached\")\n",
    "fasttext_model = fasttext.load_model(fasttext_model_path)\n",
    "\n",
    "fasttest_acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "fasttext_eval_start_time = time.time()\n",
    "for data in tqdm(tokenized_datasets['test']):\n",
    "    input = data['Text']\n",
    "    prediction = fasttext_model.predict(input)\n",
    "    fasttext_acc_metric.add_batch(predictions=[prediction], references=[lang_to_id(data['Language'])])\n",
    "fasttext_eval_end_time = time.time()\n",
    "\n",
    "fasttext_eval_acc_metric = fasttext_acc_metric.compute()\n",
    "fasttext_eval_acc_score = round(list(fasttext_metric.values())[0], 3)\n",
    "\n",
    "print(f\"fasttext eval {metric_name}: {fasttext_eval_acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85fVmkmll_ge"
   },
   "source": [
    "### Langid Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YIzFI3gmArN"
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN IN PARALLEL -- BATCHES OF 1!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GH8Nw0dm0x6"
   },
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKNMI8qim5kh"
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "stats_list = {'pt': [pt_train_end_time - pt_train_start_time,\n",
    "                     (pt_eval_end_time - pt_eval_start_time) / len(tokenized_datasets['test'],\n",
    "                     pt_eval_acc_score,\n",
    "                     pt_eval_roc_auc_score],\n",
    "              'jax': [jax_train_end_time - jax_train_start_time,\n",
    "                      (jax_eval_end_time - jax_eval_start_time) / len(tokenized_datasets['test'],\n",
    "                      jax_eval_acc_score,\n",
    "                      jax_eval_roc_auc_score]\n",
    "              'fasttext': [fasttext_train_end_time - fasttext_train_start_time,\n",
    "                    (fasttext_eval_end_time - fasttext_eval_start_time) / len(tokenized_datasets['test'],\n",
    "                    fasttext_eval_acc_score,\n",
    "                    fasttext_eval_roc_auc_score]                    \n",
    "                    \n",
    "                    'jax': ['a', 'b', 'c', 'd'], 'fasttext': [0, 0]}\n",
    "stats_list_pd = pd.DataFrame.from_dict(data)\n",
    "\n",
    "runtimes = {\n",
    "    'train'= {\n",
    "        'pt': pt_train_end_time - pt_train_start_time,\n",
    "        'jax': jax_train_end_time - jax_train_start_time,\n",
    "        'fasttext': 0\n",
    "    },\n",
    "    'inference' = {\n",
    "        'pt': pt_eval_end_time - pt_evak_start_time,\n",
    "        'jax': jax_eval_end_time - jax_eval_start_time,\n",
    "        'fasttext': 0\n",
    "    }    \n",
    "}\n",
    "\n",
    "sns.barplot(penguins, x=\"island\", y=\"body_mass_g\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v13WZoU6m4b2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "agiUvmZ1lzEv",
    "kyS6rRC_lgGY"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15c06211b1fc47718006c09c951ba009": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33aa37bed5e948138942773a41efdb10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f431a8aa6924f25ae14e1d432dca235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "423ec32b0962400583d6c00970ca8cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43710f566333424c9185ceba18ff3ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45037c38977c4a11ad72ac83d2fe993f",
      "placeholder": "​",
      "style": "IPY_MODEL_423ec32b0962400583d6c00970ca8cfc",
      "value": "Map: 100%"
     }
    },
    "45037c38977c4a11ad72ac83d2fe993f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504a496205ee409ead86ee59a55ec565": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e95917331af48c09faf9d1dfbafe915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2ff778f59c84c5f84e762fb50000db1",
      "placeholder": "​",
      "style": "IPY_MODEL_a0f7b3b956574e4b8cd0f9ff1c7a4ae5",
      "value": " 9303/9303 [00:20&lt;00:00, 409.19 examples/s]"
     }
    },
    "60ce3dd895e5468aa7fdfe9845495624": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d6ed1bfb29749fca673c486d2d0a824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ce3dd895e5468aa7fdfe9845495624",
      "max": 9303,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c328efe9a61e476a9b1f6880c57557ef",
      "value": 9303
     }
    },
    "7aaa0aea039542e1b9438ef1336a55e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d159038fd204086b153b120333bcc4f",
      "max": 1034,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_504a496205ee409ead86ee59a55ec565",
      "value": 1034
     }
    },
    "7d159038fd204086b153b120333bcc4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cc887b025b24cff8b4b8184e99ed639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43710f566333424c9185ceba18ff3ee7",
       "IPY_MODEL_6d6ed1bfb29749fca673c486d2d0a824",
       "IPY_MODEL_5e95917331af48c09faf9d1dfbafe915"
      ],
      "layout": "IPY_MODEL_a1835e1a5d884e80a126b419a69b361b"
     }
    },
    "a0f7b3b956574e4b8cd0f9ff1c7a4ae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1835e1a5d884e80a126b419a69b361b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abf65fd7765d425aa9749fe7dbe28403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33aa37bed5e948138942773a41efdb10",
      "placeholder": "​",
      "style": "IPY_MODEL_e4e03a2a6c654128a6719fee1c2fdc8a",
      "value": " 1034/1034 [00:03&lt;00:00, 291.80 examples/s]"
     }
    },
    "c328efe9a61e476a9b1f6880c57557ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c4c9e86eae6b4e4883061ec8f59305ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd0de6f58b414f0d9e156e5a7610d862",
      "placeholder": "​",
      "style": "IPY_MODEL_3f431a8aa6924f25ae14e1d432dca235",
      "value": "Map: 100%"
     }
    },
    "d2ff778f59c84c5f84e762fb50000db1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4e03a2a6c654128a6719fee1c2fdc8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb33d0aad8704f4da44e22096bfe7eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4c9e86eae6b4e4883061ec8f59305ac",
       "IPY_MODEL_7aaa0aea039542e1b9438ef1336a55e0",
       "IPY_MODEL_abf65fd7765d425aa9749fe7dbe28403"
      ],
      "layout": "IPY_MODEL_15c06211b1fc47718006c09c951ba009"
     }
    },
    "fd0de6f58b414f0d9e156e5a7610d862": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
