{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax device count: 1\n",
      "jax local device count:  1\n",
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jax\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# JAX setup\n",
    "JAX_SEED=42\n",
    "print('jax device count:', jax.device_count())  # total number of accelerator devices in the cluster\n",
    "print('jax local device count: ', jax.local_device_count())  # number of accelerator devices attached to this host\n",
    "\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyS6rRC_lgGY",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simple Speed Comparison: BERT vs JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d1ndJdHjHqg",
    "outputId": "a82dfbb9-1d11-4d42-b77f-67c5692ca15a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, FlaxBertModel\n",
    "import jax\n",
    "from jax import grad, jit\n",
    "import jax.numpy as np\n",
    "np.set_printoptions(linewidth=240)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "jax_model = FlaxBertModel.from_pretrained('bert-base-uncased')\n",
    "pt_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTxoftzOjVyE",
    "outputId": "47e548d1-eb03-4819-cf48-16daebd62b3c"
   },
   "outputs": [],
   "source": [
    "def pt_forward():\n",
    "    inputs = tokenizer(\"You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\", return_tensors=\"pt\")\n",
    "    outputs = pt_model(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "pt_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGSMrQjzjpuy",
    "outputId": "e0fb66f9-2ba2-485f-8872-5343ce8f28e3"
   },
   "outputs": [],
   "source": [
    "%timeit pt_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjZhZ9qGjqui",
    "outputId": "a4d83d32-10ee-44a9-edd7-f39c34e34454"
   },
   "outputs": [],
   "source": [
    "def jax_forward():\n",
    "    inputs = tokenizer(\"You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\", return_tensors='jax')\n",
    "    outputs = jit(jax_model)(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "jax_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58TgXoPdjt0x",
    "outputId": "9d0bd12a-2f6d-4072-cc40-2892640a67d1"
   },
   "outputs": [],
   "source": [
    "%timeit jax_forward().block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R69buRHmFA9"
   },
   "source": [
    "### Langid Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eiu3UnjmHKG",
    "outputId": "152e9215-de2e-40a8-ea83-68c8d58611ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Text', 'Language'],\n",
      "        num_rows: 9303\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Text', 'Language'],\n",
      "        num_rows: 1034\n",
      "    })\n",
      "})\n",
      "['English', 'German', 'Dutch', 'Tamil', 'Greek', 'Greek', 'French', 'Spanish', 'Russian', 'Malayalam']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from difflib import get_close_matches\n",
    "\n",
    "DATAPATH = '../../../data/langid/language_detection.csv'\n",
    "\n",
    "DATA_PERCENT_LIMIT = 100\n",
    "TEST_SPLIT = 0.1\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "split = f'train[:{DATA_PERCENT_LIMIT}%]' if DATA_PERCENT_LIMIT else 'train'\n",
    "dataset = load_dataset(\"csv\", split=split, data_files=DATAPATH, encoding='utf-8').shuffle(seed=SEED)\n",
    "dataset = dataset.train_test_split(test_size=TEST_SPLIT, seed=SEED)\n",
    "\n",
    "N_LABELS = len(set(dataset['train']['Language']))\n",
    "\n",
    "print(dataset)\n",
    "print(dataset['train'][:10]['Language'])\n",
    "\n",
    "LANG2ID = {\n",
    "    'English': 0,\n",
    "    'Malayalam': 1,\n",
    "    'Hindi': 2,\n",
    "    'Tamil': 3,\n",
    "    'Kannada': 4,\n",
    "    'French': 5,\n",
    "    'Spanish': 6,\n",
    "    'Portuguese': 7,\n",
    "    'Italian': 8,\n",
    "    'Russian': 9,\n",
    "    'Sweedish': 10,\n",
    "    'Dutch': 11,\n",
    "    'Arabic': 12,\n",
    "    'Turkish': 13,\n",
    "    'German': 14,\n",
    "    'Danish': 15,\n",
    "    'Greek': 16\n",
    "    }\n",
    "\n",
    "def lang_to_id(lang):\n",
    "      return LANG2ID[get_close_matches(lang, LANG2ID.keys())[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518,
     "referenced_widgets": [
      "9cc887b025b24cff8b4b8184e99ed639",
      "43710f566333424c9185ceba18ff3ee7",
      "6d6ed1bfb29749fca673c486d2d0a824",
      "5e95917331af48c09faf9d1dfbafe915",
      "a1835e1a5d884e80a126b419a69b361b",
      "45037c38977c4a11ad72ac83d2fe993f",
      "423ec32b0962400583d6c00970ca8cfc",
      "60ce3dd895e5468aa7fdfe9845495624",
      "c328efe9a61e476a9b1f6880c57557ef",
      "d2ff778f59c84c5f84e762fb50000db1",
      "a0f7b3b956574e4b8cd0f9ff1c7a4ae5",
      "fb33d0aad8704f4da44e22096bfe7eaf",
      "c4c9e86eae6b4e4883061ec8f59305ac",
      "7aaa0aea039542e1b9438ef1336a55e0",
      "abf65fd7765d425aa9749fe7dbe28403",
      "15c06211b1fc47718006c09c951ba009",
      "fd0de6f58b414f0d9e156e5a7610d862",
      "3f431a8aa6924f25ae14e1d432dca235",
      "7d159038fd204086b153b120333bcc4f",
      "504a496205ee409ead86ee59a55ec565",
      "33aa37bed5e948138942773a41efdb10",
      "e4e03a2a6c654128a6719fee1c2fdc8a"
     ]
    },
    "id": "bkitOldIlNYa",
    "outputId": "1cf8a6af-31ad-4afa-812e-93f29d24ad4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Text', 'Language', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 9303\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Text', 'Language', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1034\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# BERT tokenize\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    batch = tokenizer(examples['Text'], padding=\"max_length\", truncation=True)\n",
    "    batch['labels'] = [lang_to_id(lang) for lang in examples['Language']]\n",
    "    return batch\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40548-Eal6E-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PT BERT Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Psbf9FZ-5YpR",
    "outputId": "5a36fc92-720c-44e3-bdf7-a0774ae7a498"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "'''\n",
    "TRAIN_STEPS_LIMIT = -1\n",
    "N_EPOCHS = 1\n",
    "\n",
    "OUTPUT_PATH = '../models/pt'\n",
    "\n",
    "# Free memory\n",
    "gc.collect()\n",
    "\n",
    "# load pre-trained\n",
    "pt_model = BertForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=N_LABELS)\n",
    "\n",
    "# fine-tune\n",
    "log_dir = os.path.join(OUTPUT_PATH, strftime(\"%Y%m%d-%H%M\", gmtime()))\n",
    "try:\n",
    "    os.system(f'mkdir {log_dir}')\n",
    "except:\n",
    "    print('log dir exists, aborting')\n",
    "    sys.exit(1)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=log_dir,\n",
    "                                  label_names=['labels'],\n",
    "                                  num_train_epochs=N_EPOCHS,\n",
    "                                  max_steps = TRAIN_STEPS_LIMIT, #overrides num_train_epochs\n",
    "                                  per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "                                  eval_strategy=\"steps\",\n",
    "                                  eval_steps=500)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "pt_trainer = Trainer(\n",
    "    model=pt_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "pt_train_start_time = time.time()\n",
    "pt_trainer.train()\n",
    "pt_train_end_time = time.time()\n",
    "pt_train_time = pt_train_end_time - pt_train_start_time      # PT train time: 1044.08ms per iteration (9713.03s / 9303 data points)\n",
    "'''\n",
    "\n",
    "pt_train_time = 9713.03 #seconds\n",
    "print(f\"PT train time: {pt_train_time / len(tokenized_datasets['train']) * 1000:0.2f}ms per iteration \"\n",
    "      f\"({pt_train_time:0.2f}s / {len(tokenized_datasets['train'])} data points)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PT BERT Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT BERT evaluate\n",
    "\n",
    "CHECKPOINT = '../../models/langid/pt/20250318-0945/checkpoint-2326'\n",
    "\n",
    "# load saved checkpoint\n",
    "pt_checkpoint = BertForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=N_LABELS)\n",
    "\n",
    "pt_eval_trainer = Trainer(\n",
    "    model=pt_checkpoint,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "pt_eval_start_time = time.time()\n",
    "pt_eval_trainer.evaluate()\n",
    "pt_eval_end_time = time.time()\n",
    "pt_eval_time = pt_eval_end_time - pt_eval_start_time       # PT eval time: 378.33ms per iteration (391.20s / 1034 data points) \n",
    "\n",
    "print(f\"PT eval time: {pt_eval_time / len(tokenized_datasets['test']) * 1000:0.2f}ms per iteration \"\n",
    "      f\"({pt_eval_time:0.2f}s / {len(tokenized_datasets['test'])} data points)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JAX BERT Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX BERT train\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import flax\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Callable\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import traverse_util\n",
    "from flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\n",
    "from flax.training import train_state\n",
    "\n",
    "N_EPOCHS = 1\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# Free memory\n",
    "gc.collect()\n",
    "\n",
    "# setup\n",
    "num_train_steps = len(dataset['train']) // TRAIN_BATCH_SIZE * N_EPOCHS\n",
    "learning_rate_function = optax.linear_schedule(init_value=LEARNING_RATE, end_value=0, transition_steps=num_train_steps)\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    logits_function: Callable = flax.struct.field(pytree_node=False)\n",
    "    loss_function: Callable = flax.struct.field(pytree_node=False)\n",
    "\n",
    "def decay_mask_fn(params):\n",
    "    flat_params = traverse_util.flatten_dict(params)\n",
    "    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n",
    "    return traverse_util.unflatten_dict(flat_mask)\n",
    "\n",
    "def adamw(weight_decay):\n",
    "    return optax.adamw(learning_rate=learning_rate_function, b1=0.9, b2=0.999, eps=1e-6, weight_decay=weight_decay, mask=decay_mask_fn)\n",
    "\n",
    "def loss_function(logits, labels):\n",
    "  xentropy = optax.softmax_cross_entropy(logits, onehot(labels, num_classes=N_LABELS))\n",
    "  return jnp.mean(xentropy)\n",
    "     \n",
    "def eval_function(logits):\n",
    "    return logits.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias'), ('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: {('classifier', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('bert', 'pooler', 'dense', 'kernel'), ('classifier', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxBertForSequenceClassification, BertConfig\n",
    "\n",
    "# load pre-trained\n",
    "config = BertConfig.from_pretrained('google-bert/bert-base-cased', num_labels=N_LABELS)\n",
    "jax_model = FlaxBertForSequenceClassification.from_pretrained('google-bert/bert-base-cased', config=config, seed=JAX_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TrainState.create(\n",
    "    apply_fn=jax_model.__call__,\n",
    "    params=jax_model.params,\n",
    "    tx=adamw(weight_decay=0.01),\n",
    "    logits_function=eval_function,\n",
    "    loss_function=loss_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng):\n",
    "    targets = batch.pop(\"labels\")\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n",
    "\n",
    "    def loss_function(params):\n",
    "        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        loss = state.loss_function(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    grad_function = jax.value_and_grad(loss_function)\n",
    "    loss, grad = grad_function(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = jax.lax.pmean({\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}, axis_name=\"batch\")\n",
    "    return new_state, metrics, new_dropout_rng\n",
    "\n",
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n",
    "    return state.logits_function(logits)\n",
    "\n",
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(rng, dataset, batch_size):\n",
    "    steps_per_epoch = len(dataset) // batch_size\n",
    "    perms = jax.random.permutation(rng, len(dataset))\n",
    "    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    for perm in perms:\n",
    "        batch = dataset[perm]\n",
    "        del batch['Text']\n",
    "        del batch['Language']\n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "        yield batch\n",
    "\n",
    "def eval_data_loader(dataset, batch_size):\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i * batch_size : (i + 1) * batch_size]\n",
    "        del batch['Text']\n",
    "        del batch['Language']        \n",
    "        batch = {k: jnp.array(v) for k, v in batch.items()}\n",
    "        batch = shard(batch)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = flax.jax_utils.replicate(state)\n",
    "num_labels = flax.jax_utils.replicate(N_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(JAX_SEED)\n",
    "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n",
    "\n",
    "#for i, epoch in enumerate(tqdm(range(1, N_EPOCHS + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n",
    "rng, input_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d49f559cae84f5a8c4b313f5134b070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/2325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax train time: 46.78ms per iteration (435.23s / 9303 data points)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../../../models/JAX/langid/jax/20250318-1737/tokenizer_config.json',\n",
       " '../../../models/JAX/langid/jax/20250318-1737/special_tokens_map.json',\n",
       " '../../../models/JAX/langid/jax/20250318-1737/vocab.txt',\n",
       " '../../../models/JAX/langid/jax/20250318-1737/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JAX train\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "jax_train_start_time = time.time()\n",
    "with tqdm(total=len(tokenized_datasets['train']) // TRAIN_BATCH_SIZE, desc=\"Training...\", leave=False) as progress_bar_train:\n",
    "  for batch in train_data_loader(input_rng, tokenized_datasets['train'], TRAIN_BATCH_SIZE):\n",
    "    state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n",
    "jax_train_end_time = time.time()\n",
    "jax_train_time = jax_train_end_time - jax_train_start_time ## Jax train time: 44.10ms per iteration (410.22s / 9303 data points)\n",
    "\n",
    "print(f\"Jax train time: {jax_train_time / len(tokenized_datasets['train']) * 1000:0.2f}ms per iteration \"\n",
    "      f\"({jax_train_time:0.2f}s / {len(tokenized_datasets['train'])} data points)\")\n",
    "\n",
    "# save model\n",
    "OUTPUT_PATH = '../../../models/JAX/langid/jax'\n",
    "log_dir = os.path.join(OUTPUT_PATH, strftime(\"%Y%m%d-%H%M\", gmtime()))\n",
    "try:\n",
    "    os.system(f'mkdir {log_dir}')\n",
    "except:\n",
    "    print('log dir exists')\n",
    "\n",
    "jax_model.save_pretrained(log_dir)\n",
    "tokenizer.save_pretrained(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JAX BERT Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_LABELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m CHECKPOINT = \u001b[33m'\u001b[39m\u001b[33m../../../models/JAX/langid/jax/20250318-1737/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# load saved checkpoint\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m config = BertConfig.from_pretrained(CHECKPOINT, num_labels=\u001b[43mN_LABELS\u001b[49m)\n\u001b[32m     20\u001b[39m jax_checkpoint = jit(FlaxBertForSequenceClassification.from_pretrained(CHECKPOINT, config=config, seed=JAX_SEED))\n\u001b[32m     21\u001b[39m jax_tokenizer = BertTokenizer.from_pretrained(CHECKPOINT)\n",
      "\u001b[31mNameError\u001b[39m: name 'N_LABELS' is not defined"
     ]
    }
   ],
   "source": [
    "# JAX evaluate\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from jax import jit\n",
    "\n",
    "from transformers import FlaxBertForSequenceClassification, BertConfig, BertTokenizer\n",
    "import evaluate\n",
    "\n",
    "\n",
    "EVAL_BATCH_SIZE = 2\n",
    "\n",
    "CHECKPOINT = '../../../models/JAX/langid/jax/20250318-1737/'\n",
    "\n",
    "# load saved checkpoint\n",
    "config = BertConfig.from_pretrained(CHECKPOINT, num_labels=N_LABELS)\n",
    "jax_checkpoint = jit(FlaxBertForSequenceClassification.from_pretrained(CHECKPOINT, config=config, seed=JAX_SEED))\n",
    "jax_tokenizer = BertTokenizer.from_pretrained(CHECKPOINT)\n",
    "\n",
    "jax_acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# evaluate\n",
    "jax_eval_start_time = time.time()\n",
    "for data in tqdm(tokenized_datasets['test']):\n",
    "    #print(data)\n",
    "    texts = data['Text']\n",
    "    labels = [[lang_to_id(data['Language'])]]\n",
    "    inputs = jax_tokenizer(texts, return_tensors='jax', padding=\"max_length\", truncation=True)\n",
    "    predictions = jax_checkpoint(**inputs)\n",
    "    jax_acc_metric.add_batch(predictions=list(itertools.chain.from_iterable(predictions)), references=list(itertools.chain.from_iterable(labels)))\n",
    "    break\n",
    "jax_eval_end_time = time.time()\n",
    "jax_eval_time = jax_eval_end_time - jax_eval_start_time     #Jax eval time: 19.69ms per iteration (20.36s / 1034 data points)\n",
    "\n",
    "print(f\"Jax eval time: {jax_eval_time / len(tokenized_datasets['test']) * 1000:0.2f}ms per iteration \"\n",
    "      f\"({jax_eval_time:0.2f}s / {len(tokenized_datasets['test'])} data points)\")\n",
    "\n",
    "jax_eval_acc_metric = jax_acc_metric.compute()\n",
    "\n",
    "loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n",
    "jax_eval_acc_score = round(list(eval_metric.values())[0], 3)  #Eval accuracy: 0.918\n",
    "metric_name = list(eval_metric.keys())[0]\n",
    "\n",
    "print(f\"Eval {metric_name}: {jax_eval_acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjCBNlOJntdV"
   },
   "source": [
    "### Fasttext Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import fasttext\n",
    "from difflib import get_close_matches\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "'''\n",
    "LANG2ID = {\n",
    "    '__label__eng': 0,\n",
    "    'Malayalam': 1,\n",
    "    'Hindi': 2,\n",
    "    'Tamil': 3,\n",
    "    'Kannada': 4,\n",
    "    'French': 5,\n",
    "    'Spanish': 6,\n",
    "    'Portuguese': 7,\n",
    "    'Italian': 8,\n",
    "    'Russian': 9,\n",
    "    'Sweedish': 10,\n",
    "    'Dutch': 11,\n",
    "    'Arabic': 12,\n",
    "    'Turkish': 13,\n",
    "    'German': 14,\n",
    "    'Danish': 15,\n",
    "    'Greek': 16\n",
    "    }\n",
    "\n",
    "def lang_to_id(lang):\n",
    "      return LANG2ID[get_close_matches(lang, LANG2ID.keys())[0]]\n",
    "\n",
    "\n",
    "'__label__eng_Latn'\n",
    "af als am an ar arz as ast av az azb ba bar bcl be bg bh bn bo bpy br bs bxr ca cbk ce ceb ckb co cs cv cy da de diq dsb dty dv el eml en eo es et eu fa fi fr frr fy ga gd gl gn gom gu gv he hi hif hr hsb ht hu hy ia id ie ilo io is it ja jbo jv ka kk km kn ko krc ku kv kw ky la lb lez li lmo lo lrc lt lv mai mg mhr min mk ml mn mr mrj ms mt mwl my myv mzn nah nap nds ne new nl nn no oc or os pa pam pfl pl pms pnb ps pt qu rm ro ru rue sa sah sc scn sco sd sh si sk sl so sq sr su sv sw ta te tg th tk tl tr tt tyv ug uk ur uz vec vep vi vls vo wa war wuu xal xmf yi yo yue zh\n",
    "'''\n",
    "\n",
    "fasttext_model_path = hf_hub_download(repo_id=\"facebook/fasttext-language-identification\", \n",
    "                                      filename=\"model.bin\", \n",
    "                                      cache_dir=\"../../models/langid/fasttext/cached\")\n",
    "fasttext_model = fasttext.load_model(fasttext_model_path)\n",
    "\n",
    "fasttest_acc_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "fasttext_eval_start_time = time.time()\n",
    "for data in tqdm(tokenized_datasets['test']):\n",
    "    input = data['Text']\n",
    "    prediction = fasttext_model.predict(input)\n",
    "    fasttext_acc_metric.add_batch(predictions=[prediction], references=[lang_to_id(data['Language'])])\n",
    "fasttext_eval_end_time = time.time()\n",
    "\n",
    "fasttext_eval_acc_metric = fasttext_acc_metric.compute()\n",
    "fasttext_eval_acc_score = round(list(fasttext_metric.values())[0], 3)\n",
    "\n",
    "print(f\"fasttext eval {metric_name}: {fasttext_eval_acc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85fVmkmll_ge"
   },
   "source": [
    "### Langid Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YIzFI3gmArN"
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN IN PARALLEL -- BATCHES OF 1!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GH8Nw0dm0x6"
   },
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKNMI8qim5kh"
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "stats_list = {'pt': [pt_train_end_time - pt_train_start_time,\n",
    "                     (pt_eval_end_time - pt_eval_start_time) / len(tokenized_datasets['test'],\n",
    "                     pt_eval_acc_score,\n",
    "                     pt_eval_roc_auc_score],\n",
    "              'jax': [jax_train_end_time - jax_train_start_time,\n",
    "                      (jax_eval_end_time - jax_eval_start_time) / len(tokenized_datasets['test'],\n",
    "                      jax_eval_acc_score,\n",
    "                      jax_eval_roc_auc_score]\n",
    "              'fasttext': [fasttext_train_end_time - fasttext_train_start_time,\n",
    "                    (fasttext_eval_end_time - fasttext_eval_start_time) / len(tokenized_datasets['test'],\n",
    "                    fasttext_eval_acc_score,\n",
    "                    fasttext_eval_roc_auc_score]                    \n",
    "                    \n",
    "                    'jax': ['a', 'b', 'c', 'd'], 'fasttext': [0, 0]}\n",
    "stats_list_pd = pd.DataFrame.from_dict(data)\n",
    "\n",
    "runtimes = {\n",
    "    'train'= {\n",
    "        'pt': pt_train_end_time - pt_train_start_time,\n",
    "        'jax': jax_train_end_time - jax_train_start_time,\n",
    "        'fasttext': 0\n",
    "    },\n",
    "    'inference' = {\n",
    "        'pt': pt_eval_end_time - pt_evak_start_time,\n",
    "        'jax': jax_eval_end_time - jax_eval_start_time,\n",
    "        'fasttext': 0\n",
    "    }    \n",
    "}\n",
    "\n",
    "sns.barplot(penguins, x=\"island\", y=\"body_mass_g\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v13WZoU6m4b2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "agiUvmZ1lzEv",
    "kyS6rRC_lgGY"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15c06211b1fc47718006c09c951ba009": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33aa37bed5e948138942773a41efdb10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f431a8aa6924f25ae14e1d432dca235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "423ec32b0962400583d6c00970ca8cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43710f566333424c9185ceba18ff3ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45037c38977c4a11ad72ac83d2fe993f",
      "placeholder": "​",
      "style": "IPY_MODEL_423ec32b0962400583d6c00970ca8cfc",
      "value": "Map: 100%"
     }
    },
    "45037c38977c4a11ad72ac83d2fe993f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504a496205ee409ead86ee59a55ec565": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e95917331af48c09faf9d1dfbafe915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2ff778f59c84c5f84e762fb50000db1",
      "placeholder": "​",
      "style": "IPY_MODEL_a0f7b3b956574e4b8cd0f9ff1c7a4ae5",
      "value": " 9303/9303 [00:20&lt;00:00, 409.19 examples/s]"
     }
    },
    "60ce3dd895e5468aa7fdfe9845495624": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d6ed1bfb29749fca673c486d2d0a824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ce3dd895e5468aa7fdfe9845495624",
      "max": 9303,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c328efe9a61e476a9b1f6880c57557ef",
      "value": 9303
     }
    },
    "7aaa0aea039542e1b9438ef1336a55e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d159038fd204086b153b120333bcc4f",
      "max": 1034,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_504a496205ee409ead86ee59a55ec565",
      "value": 1034
     }
    },
    "7d159038fd204086b153b120333bcc4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cc887b025b24cff8b4b8184e99ed639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43710f566333424c9185ceba18ff3ee7",
       "IPY_MODEL_6d6ed1bfb29749fca673c486d2d0a824",
       "IPY_MODEL_5e95917331af48c09faf9d1dfbafe915"
      ],
      "layout": "IPY_MODEL_a1835e1a5d884e80a126b419a69b361b"
     }
    },
    "a0f7b3b956574e4b8cd0f9ff1c7a4ae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1835e1a5d884e80a126b419a69b361b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abf65fd7765d425aa9749fe7dbe28403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33aa37bed5e948138942773a41efdb10",
      "placeholder": "​",
      "style": "IPY_MODEL_e4e03a2a6c654128a6719fee1c2fdc8a",
      "value": " 1034/1034 [00:03&lt;00:00, 291.80 examples/s]"
     }
    },
    "c328efe9a61e476a9b1f6880c57557ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c4c9e86eae6b4e4883061ec8f59305ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd0de6f58b414f0d9e156e5a7610d862",
      "placeholder": "​",
      "style": "IPY_MODEL_3f431a8aa6924f25ae14e1d432dca235",
      "value": "Map: 100%"
     }
    },
    "d2ff778f59c84c5f84e762fb50000db1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4e03a2a6c654128a6719fee1c2fdc8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb33d0aad8704f4da44e22096bfe7eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4c9e86eae6b4e4883061ec8f59305ac",
       "IPY_MODEL_7aaa0aea039542e1b9438ef1336a55e0",
       "IPY_MODEL_abf65fd7765d425aa9749fe7dbe28403"
      ],
      "layout": "IPY_MODEL_15c06211b1fc47718006c09c951ba009"
     }
    },
    "fd0de6f58b414f0d9e156e5a7610d862": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
